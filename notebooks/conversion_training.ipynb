{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3f3bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (132379, 14)\n",
      "\n",
      "Columns: ['year', 'month', 'day', 'order', 'country', 'session_id', 'page1_main_category', 'page2_clothing_model', 'colour', 'location', 'model_photography', 'price', 'price_2', 'page']\n",
      "\n",
      "First 5 rows:\n",
      "    year  month  day  order  country  session_id  page1_main_category  \\\n",
      "0  2008      6   22     21       29       15648                    3   \n",
      "1  2008      5   19      6       29       10018                    2   \n",
      "2  2008      7   15      2       29       19388                    3   \n",
      "3  2008      5    2      2       29        7181                    2   \n",
      "4  2008      6    9     16       29       13493                    2   \n",
      "\n",
      "  page2_clothing_model  colour  location  model_photography  price  price_2  \\\n",
      "0                  C20      13         1                  2     48        1   \n",
      "1                  B26      13         3                  1     57        1   \n",
      "2                  C13       9         5                  1     48        1   \n",
      "3                  B11       2         4                  1     43        2   \n",
      "4                  B31       9         5                  1     57        1   \n",
      "\n",
      "   page  \n",
      "0     2  \n",
      "1     2  \n",
      "2     1  \n",
      "3     1  \n",
      "4     2  \n",
      "\n",
      "Data Types:\n",
      " year                     int64\n",
      "month                    int64\n",
      "day                      int64\n",
      "order                    int64\n",
      "country                  int64\n",
      "session_id               int64\n",
      "page1_main_category      int64\n",
      "page2_clothing_model    object\n",
      "colour                   int64\n",
      "location                 int64\n",
      "model_photography        int64\n",
      "price                    int64\n",
      "price_2                  int64\n",
      "page                     int64\n",
      "dtype: object\n",
      "\n",
      "Missing Values:\n",
      " year                    0\n",
      "month                   0\n",
      "day                     0\n",
      "order                   0\n",
      "country                 0\n",
      "session_id              0\n",
      "page1_main_category     0\n",
      "page2_clothing_model    0\n",
      "colour                  0\n",
      "location                0\n",
      "model_photography       0\n",
      "price                   0\n",
      "price_2                 0\n",
      "page                    0\n",
      "dtype: int64\n",
      "\n",
      "Statistical Summary:\n",
      "            year          month            day          order        country  \\\n",
      "count  132379.0  132379.000000  132379.000000  132379.000000  132379.000000   \n",
      "mean     2008.0       5.582759      14.507671       9.811314      26.949629   \n",
      "std         0.0       1.328064       8.829106      13.458937       7.153071   \n",
      "min      2008.0       4.000000       1.000000       1.000000       1.000000   \n",
      "25%      2008.0       4.000000       7.000000       2.000000      29.000000   \n",
      "50%      2008.0       5.000000      14.000000       6.000000      29.000000   \n",
      "75%      2008.0       7.000000      22.000000      12.000000      29.000000   \n",
      "max      2008.0       8.000000      31.000000     195.000000      47.000000   \n",
      "\n",
      "          session_id  page1_main_category         colour       location  \\\n",
      "count  132379.000000        132379.000000  132379.000000  132379.000000   \n",
      "mean    12038.722063             2.400426       6.227393       3.261106   \n",
      "std      7012.460866             1.145004       4.238354       1.714058   \n",
      "min         1.000000             1.000000       1.000000       1.000000   \n",
      "25%      5905.000000             1.000000       3.000000       2.000000   \n",
      "50%     11931.000000             2.000000       4.000000       3.000000   \n",
      "75%     18212.000000             3.000000       9.000000       5.000000   \n",
      "max     24026.000000             4.000000      14.000000       6.000000   \n",
      "\n",
      "       model_photography          price        price_2           page  \n",
      "count      132379.000000  132379.000000  132379.000000  132379.000000  \n",
      "mean            1.260026      43.788191       1.488484       1.712137  \n",
      "std             0.438650      12.539390       0.499869       0.983699  \n",
      "min             1.000000      18.000000       1.000000       1.000000  \n",
      "25%             1.000000      33.000000       1.000000       1.000000  \n",
      "50%             1.000000      43.000000       1.000000       1.000000  \n",
      "75%             2.000000      52.000000       2.000000       2.000000  \n",
      "max             2.000000      82.000000       2.000000       5.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Clickstream_customer_analysis\\data\\train_data (1).csv\") \n",
    "\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\\n\", df.head())\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nStatistical Summary:\\n\", df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e24b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing columns: ['converted', 'revenue']\n"
     ]
    }
   ],
   "source": [
    "required_columns = ['converted', 'revenue']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "if missing_columns:\n",
    "    print(\"Missing columns:\", missing_columns)\n",
    "else:\n",
    "    print(\"All required columns are present.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3843957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   converted  revenue\n",
      "0          0     0.00\n",
      "1          1    22.22\n",
      "2          0     0.00\n",
      "3          0     0.00\n",
      "4          0     0.00\n",
      "\n",
      "Target Distribution:\n",
      " converted\n",
      "0    119380\n",
      "1     12999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Revenue Summary:\n",
      " count    132379.000000\n",
      "mean          2.726596\n",
      "std           9.217200\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max          50.000000\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "df['converted'] = np.random.choice([0, 1], size=len(df), p=[0.9, 0.1])\n",
    "df['revenue'] = df['converted'].apply(lambda x: round(np.random.uniform(5, 50), 2) if x == 1 else 0.0)\n",
    "\n",
    "print(df[['converted', 'revenue']].head())\n",
    "print(\"\\nTarget Distribution:\\n\", df['converted'].value_counts())\n",
    "print(\"\\nRevenue Summary:\\n\", df['revenue'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bde843d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Encoded Values for 'page2_clothing_model': 216\n",
      "   page2_clothing_model\n",
      "0                    88\n",
      "1                    60\n",
      "2                    80\n",
      "3                    45\n",
      "4                    66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_encoded = df.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "df_encoded['page2_clothing_model'] = le.fit_transform(df_encoded['page2_clothing_model'])\n",
    "\n",
    "print(\"Unique Encoded Values for 'page2_clothing_model':\", df_encoded['page2_clothing_model'].nunique())\n",
    "print(df_encoded[['page2_clothing_model']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabd3f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month       day     order   country  page1_main_category  \\\n",
      "0  0.314174  0.848597  0.831323  0.286643             0.523645   \n",
      "1 -0.438805  0.508811 -0.283182  0.286643            -0.349717   \n",
      "2  1.067153  0.055762 -0.580383  0.286643             0.523645   \n",
      "3 -0.438805 -1.416646 -0.580383  0.286643            -0.349717   \n",
      "4  0.314174 -0.623811  0.459822  0.286643            -0.349717   \n",
      "\n",
      "   page2_clothing_model    colour  location  model_photography     price  \\\n",
      "0              0.091727  1.597940 -1.319159           1.686940  0.335888   \n",
      "1             -0.383512  1.597940 -0.152333          -0.592789  1.053629   \n",
      "2             -0.044055  0.654173  1.014493          -0.592789  0.335888   \n",
      "3             -0.638105 -0.997418  0.431080          -0.592789 -0.062857   \n",
      "4             -0.281675  0.654173  1.014493          -0.592789  1.053629   \n",
      "\n",
      "    price_2      page  \n",
      "0 -0.977227  0.292634  \n",
      "1 -0.977227  0.292634  \n",
      "2 -0.977227 -0.723941  \n",
      "3  1.023304 -0.723941  \n",
      "4 -0.977227  0.292634  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df_scaled = df_encoded.copy()\n",
    "\n",
    "numerical_cols = ['month', 'day', 'order', 'country', 'page1_main_category',\n",
    "                  'page2_clothing_model', 'colour', 'location', 'model_photography',\n",
    "                  'price', 'price_2', 'page']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled[numerical_cols] = scaler.fit_transform(df_scaled[numerical_cols])\n",
    "\n",
    "print(df_scaled[numerical_cols].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a387e1b",
   "metadata": {},
   "source": [
    " Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3deaa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   session_id  session_length  num_clicks\n",
      "0       15648              84          84\n",
      "1       10018               9           9\n",
      "2       19388              10          10\n",
      "3        7181               6           6\n",
      "4       13493              15          15\n"
     ]
    }
   ],
   "source": [
    "session_click_counts = df.groupby('session_id').size().rename(\"session_length\")\n",
    "\n",
    "df = df.merge(session_click_counts, on='session_id', how='left')\n",
    "\n",
    "df['num_clicks'] = df['session_length']\n",
    "\n",
    "print(df[['session_id', 'session_length', 'num_clicks']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f847f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   category_1_clicks  category_2_clicks  category_3_clicks  category_4_clicks\n",
      "0                 35                 11                 36                  2\n",
      "1                  2                  7                  0                  0\n",
      "2                  3                  0                  5                  2\n",
      "3                  0                  5                  1                  0\n",
      "4                  0                 14                  1                  0\n"
     ]
    }
   ],
   "source": [
    "category_clicks = df.groupby(['session_id', 'page1_main_category']).size().unstack(fill_value=0)\n",
    "\n",
    "category_clicks.columns = [f'category_{int(col)}_clicks' for col in category_clicks.columns]\n",
    "\n",
    "df = df.merge(category_clicks, on='session_id', how='left')\n",
    "\n",
    "print(df[[col for col in df.columns if 'category_' in col]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dca9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is_bounce  exit_page  repeated_views\n",
      "0          0          4               1\n",
      "1          0          2               1\n",
      "2          0          3               1\n",
      "3          0          2               1\n",
      "4          0          2               1\n"
     ]
    }
   ],
   "source": [
    "df['is_bounce'] = df['session_length'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "exit_pages = df.groupby('session_id')['page'].max().reset_index()\n",
    "exit_pages.rename(columns={'page': 'exit_page'}, inplace=True)\n",
    "df = df.merge(exit_pages, on='session_id', how='left')\n",
    "\n",
    "repeats = df.groupby(['session_id', 'page2_clothing_model']).size().reset_index(name='count')\n",
    "repeats_flag = repeats[repeats['count'] > 1]['session_id'].unique()\n",
    "df['repeated_views'] = df['session_id'].apply(lambda x: 1 if x in repeats_flag else 0)\n",
    "\n",
    "print(df[['is_bounce', 'exit_page', 'repeated_views']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e3f2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Features Shape: (132379, 21)\n",
      " Classification Target Shape: (132379,)\n",
      " Regression Target Shape: (132379,)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = ['year', 'session_id', 'converted', 'revenue']\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "\n",
    "y_classification = df['converted']\n",
    "\n",
    "y_regression = df['revenue']\n",
    "\n",
    "print(\" Final Features Shape:\", X.shape)\n",
    "print(\" Classification Target Shape:\", y_classification.shape)\n",
    "print(\" Regression Target Shape:\", y_regression.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f388f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Train Shape: (105903, 21) (105903,)\n",
      "Classification Test Shape: (26476, 21) (26476,)\n",
      "Regression Train Shape: (105903, 21) (105903,)\n",
      "Regression Test Shape: (26476, 21) (26476,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_classification, test_size=0.2, stratify=y_classification, random_state=42)\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Classification Train Shape:\", X_train_clf.shape, y_train_clf.shape)\n",
    "print(\"Classification Test Shape:\", X_test_clf.shape, y_test_clf.shape)\n",
    "\n",
    "print(\"Regression Train Shape:\", X_train_reg.shape, y_train_reg.shape)\n",
    "print(\"Regression Test Shape:\", X_test_reg.shape, y_test_reg.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe3048a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " After SMOTE:\n",
      "Class 0: 95504\n",
      "Class 1: 95504\n",
      "Balanced X shape: (191008, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df['page2_clothing_model'] = LabelEncoder().fit_transform(df['page2_clothing_model'])\n",
    "\n",
    "drop_cols = ['year', 'session_id', 'converted', 'revenue']\n",
    "X = df.drop(columns=drop_cols)\n",
    "y_classification = df['converted']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_classification, test_size=0.2, random_state=42, stratify=y_classification\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_clf_bal, y_train_clf_bal = smote.fit_resample(X_train_clf, y_train_clf)\n",
    "\n",
    "print(\" After SMOTE:\")\n",
    "print(\"Class 0:\", sum(y_train_clf_bal == 0))\n",
    "print(\"Class 1:\", sum(y_train_clf_bal == 1))\n",
    "print(\"Balanced X shape:\", X_train_clf_bal.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c21e3f",
   "metadata": {},
   "source": [
    "MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cedc454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Confusion Matrix:\n",
      " [[23321   555]\n",
      " [ 2528    72]]\n",
      " Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     23876\n",
      "           1       0.11      0.03      0.04      2600\n",
      "\n",
      "    accuracy                           0.88     26476\n",
      "   macro avg       0.51      0.50      0.49     26476\n",
      "weighted avg       0.82      0.88      0.85     26476\n",
      "\n",
      "ROC-AUC Score: 0.4969030535974329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Clickstream_customer_analysis\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_clf_bal, y_train_clf_bal)\n",
    "\n",
    "y_pred_logreg = log_reg.predict(X_test_clf)\n",
    "\n",
    "print(\" Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_logreg))\n",
    "print(\" Classification Report:\\n\", classification_report(y_test_clf, y_pred_logreg))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test_clf, log_reg.predict_proba(X_test_clf)[:, 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9fd47e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[22006  1870]\n",
      " [ 2398   202]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.92      0.91     23876\n",
      "           1       0.10      0.08      0.09      2600\n",
      "\n",
      "    accuracy                           0.84     26476\n",
      "   macro avg       0.50      0.50      0.50     26476\n",
      "weighted avg       0.82      0.84      0.83     26476\n",
      "\n",
      "ROC-AUC Score: 0.4994577029395467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train_clf_bal, y_train_clf_bal)\n",
    "\n",
    "y_pred_rf = rf_clf.predict(X_test_clf)\n",
    "y_proba_rf = rf_clf.predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_clf, y_pred_rf))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test_clf, y_proba_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4f16fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[20300  3576]\n",
      " [ 2217   383]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88     23876\n",
      "           1       0.10      0.15      0.12      2600\n",
      "\n",
      "    accuracy                           0.78     26476\n",
      "   macro avg       0.50      0.50      0.50     26476\n",
      "weighted avg       0.82      0.78      0.80     26476\n",
      "\n",
      "\n",
      "ROC-AUC Score: 0.49852146345863885\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "xgb_clf.fit(X_train_clf_bal, y_train_clf_bal)\n",
    "\n",
    "y_pred_xgb = xgb_clf.predict(X_test_clf)\n",
    "y_proba_xgb = xgb_clf.predict_proba(X_test_clf)[:, 1]\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_clf, y_pred_xgb))\n",
    "print(\"\\nROC-AUC Score:\", roc_auc_score(y_test_clf, y_proba_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb8f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight: 9.18\n",
      "Confusion Matrix:\n",
      " [[14532  9344]\n",
      " [ 1581  1019]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.61      0.73     23876\n",
      "           1       0.10      0.39      0.16      2600\n",
      "\n",
      "    accuracy                           0.59     26476\n",
      "   macro avg       0.50      0.50      0.44     26476\n",
      "weighted avg       0.82      0.59      0.67     26476\n",
      "\n",
      "ROC-AUC Score: 0.500283870510458\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "class_0 = sum(y_train_clf == 0)\n",
    "class_1 = sum(y_train_clf == 1)\n",
    "scale_pos_weight = class_0 / class_1\n",
    "print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "xgb_model_weighted = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model_weighted.fit(X_train_clf, y_train_clf)\n",
    "y_pred_weighted = xgb_model_weighted.predict(X_test_clf)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_clf, y_pred_weighted))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_clf, y_pred_weighted))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test_clf, y_pred_weighted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a053c6",
   "metadata": {},
   "source": [
    "REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e053c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   converted  price  session_length  num_clicks  revenue\n",
      "0          0     48              84          84     0.00\n",
      "1          1     57               9           9    37.52\n",
      "2          0     48              10          10     0.00\n",
      "3          0     43               6           6     0.00\n",
      "4          0     57              15          15     0.00\n",
      "\n",
      "Revenue Summary:\n",
      " count    132379.000000\n",
      "mean          3.182146\n",
      "std          10.140807\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max         109.180000\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "price_weight = 0.6\n",
    "session_length_weight = 0.2\n",
    "click_weight = 0.2\n",
    "\n",
    "df['revenue'] = df['converted'] * (\n",
    "    (df['price'] * price_weight) +\n",
    "    (df['session_length'] * session_length_weight) +\n",
    "    (df['num_clicks'] * click_weight) +\n",
    "    np.random.normal(loc=0, scale=2, size=len(df))  \n",
    ")\n",
    "\n",
    "df['revenue'] = df['revenue'].clip(lower=0).round(2)\n",
    "\n",
    "print(df[['converted', 'price', 'session_length', 'num_clicks', 'revenue']].head())\n",
    "print(\"\\nRevenue Summary:\\n\", df['revenue'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7eaa9cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "all_values = pd.concat([X_train_reg['page2_clothing_model'], X_test_reg['page2_clothing_model']])\n",
    "le.fit(all_values)\n",
    "\n",
    "X_train_reg['page2_clothing_model'] = le.transform(X_train_reg['page2_clothing_model'])\n",
    "X_test_reg['page2_clothing_model'] = le.transform(X_test_reg['page2_clothing_model'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60049d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.6989\n",
      "MSE: 100.0389\n",
      "RMSE: 10.0019\n",
      "R² Score: 0.0090\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, df['revenue'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "y_pred_reg = lr_model.predict(X_test_reg)\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
    "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2407646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of converted dataset: (12999, 25)\n",
      "Revenue summary:\n",
      " count    12999.000000\n",
      "mean        32.406290\n",
      "std         10.010638\n",
      "min          9.370000\n",
      "25%         25.320000\n",
      "50%         31.230000\n",
      "75%         38.060000\n",
      "max        109.180000\n",
      "Name: revenue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_converted = df[df['converted'] == 1].copy()\n",
    "\n",
    "print(\"Shape of converted dataset:\", df_converted.shape)\n",
    "print(\"Revenue summary:\\n\", df_converted['revenue'].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
